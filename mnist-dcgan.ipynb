{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport numpy as np\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchvision import datasets\nfrom torchvision.utils import save_image\nfrom torch.autograd import Variable\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2022-05-29T12:35:09.634673Z","iopub.execute_input":"2022-05-29T12:35:09.635576Z","iopub.status.idle":"2022-05-29T12:35:11.583626Z","shell.execute_reply.started":"2022-05-29T12:35:09.635471Z","shell.execute_reply":"2022-05-29T12:35:11.582813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-------basic GAN--------\n'''\n####model architecture####\n-- define generator\n-- define discriminator\n-- adversarial loss\n-- gen optimizer\n-- discr optimizer\n\n####training loop####\n##genrator training##\n-- generate noise vector\n-- noise vector --> generator --> fake output\n-- gen loss --> adv loss --> disc (fake, real)\n-- gen optimizer steps\n##discriminator training##\n-- real loss --> adv loss --> real images\n-- fake loss --> adv loss --> fake/generator images\n-- final loss --> (real loss + fake loss)/2\n-- dicriminator optimizer step\n'''\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = 'cuda'\nbatch_size = 64\nepochs = 200\nz_dim=100\nsample_interval = 100 #400\nLR = 0.0002\nB1 = 0.5\nB2 = 0.999\nIMG_SIZE = 32\nCHANNELS = 3","metadata":{"execution":{"iopub.status.busy":"2022-05-29T07:03:49.502962Z","iopub.execute_input":"2022-05-29T07:03:49.503341Z","iopub.status.idle":"2022-05-29T07:03:49.508117Z","shell.execute_reply.started":"2022-05-29T07:03:49.503301Z","shell.execute_reply":"2022-05-29T07:03:49.507143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataloader","metadata":{}},{"cell_type":"code","source":"!mkdir mnist","metadata":{"execution":{"iopub.status.busy":"2022-05-28T04:40:40.340542Z","iopub.execute_input":"2022-05-28T04:40:40.341301Z","iopub.status.idle":"2022-05-28T04:40:40.992401Z","shell.execute_reply.started":"2022-05-28T04:40:40.341265Z","shell.execute_reply":"2022-05-28T04:40:40.990921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataloader = torch.utils.data.DataLoader(\n    datasets.MNIST(\n        \"./mnist\",\n        train=True,\n        download=True,\n        transform=transforms.Compose(\n            [transforms.Resize(IMG_SIZE), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n        ),\n    ),\n    batch_size=batch_size,\n    shuffle=True,\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-29T07:01:51.412592Z","iopub.execute_input":"2022-05-29T07:01:51.413202Z","iopub.status.idle":"2022-05-29T07:03:40.110573Z","shell.execute_reply.started":"2022-05-29T07:01:51.413162Z","shell.execute_reply":"2022-05-29T07:03:40.10965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nimg_shape = None\nfor img,_ in dataloader_1:\n    img_shape = img.shape\n    break\n\nimg_shape = np.array(img_shape)\nint(np.prod(img_shape[1:]))\n'''","metadata":{"execution":{"iopub.status.busy":"2022-05-28T17:21:29.492108Z","iopub.execute_input":"2022-05-28T17:21:29.492851Z","iopub.status.idle":"2022-05-28T17:21:30.007399Z","shell.execute_reply.started":"2022-05-28T17:21:29.49281Z","shell.execute_reply":"2022-05-28T17:21:30.006486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generator and Discriminator","metadata":{}},{"cell_type":"code","source":"def noise_vector(batch_size, dim):\n    return torch.randn(batch_size, dim, device=device)\n\n\nclass Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n        \n        self.init_size = IMG_SIZE // 4\n        self.linear = nn.Sequential(nn.Linear(z_dim, 128 * self.init_size ** 2))\n        self.conv = nn.Sequential(\n            nn.BatchNorm2d(128),\n            nn.Upsample(scale_factor=2),\n            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n            nn.BatchNorm2d(128, 0.8),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Upsample(scale_factor=2),\n            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n            nn.BatchNorm2d(64, 0.8),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(64, CHANNELS, 3, stride=1, padding=1),\n            nn.Tanh(),\n        )  \n        \n    def forward(self, noise):\n        img = self.linear(noise)\n        img = img.view(img.size(0), 128, self.init_size, self.init_size)\n        out = self.conv(img)\n        #print(out.shape)\n        return out\n        \n    \n\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        \n        def discriminator_block(in_filters, out_filters, bn=True):\n            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]\n            if bn:\n                block.append(nn.BatchNorm2d(out_filters, 0.8))\n            return block\n\n        self.model = nn.Sequential(\n            *discriminator_block(CHANNELS, 16, bn=False),\n            *discriminator_block(16, 32),\n            *discriminator_block(32, 64),\n            *discriminator_block(64, 128)\n        )\n\n        # The height and width of downsampled image\n        ds_size = IMG_SIZE // 2 ** 4\n        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, 1), nn.Sigmoid())\n\n        \n    def forward(self, img):\n        out = self.model(img)\n        #print(out.shape)\n        out = out.view(out.shape[0], -1)\n        #print(out.shape)\n        output = self.adv_layer(out)\n\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-05-29T07:03:55.347464Z","iopub.execute_input":"2022-05-29T07:03:55.347822Z","iopub.status.idle":"2022-05-29T07:03:55.492458Z","shell.execute_reply.started":"2022-05-29T07:03:55.347792Z","shell.execute_reply":"2022-05-29T07:03:55.491379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"adv_loss = nn.BCELoss()\n\ngen = Generator()\ndis = Discriminator()\n\ngen.cuda()\ndis.cuda()\nadv_loss.cuda()\n\ngen_opt = torch.optim.Adam(gen.parameters(), lr=LR, betas=(B1, B2))\ndis_opt = torch.optim.Adam(dis.parameters(), lr=LR, betas=(B1, B2))\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-29T07:04:02.428388Z","iopub.execute_input":"2022-05-29T07:04:02.428995Z","iopub.status.idle":"2022-05-29T07:04:05.341574Z","shell.execute_reply.started":"2022-05-29T07:04:02.428958Z","shell.execute_reply":"2022-05-29T07:04:05.340749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"!mkdir images","metadata":{"execution":{"iopub.status.busy":"2022-05-29T07:04:07.886511Z","iopub.execute_input":"2022-05-29T07:04:07.88686Z","iopub.status.idle":"2022-05-29T07:04:08.599095Z","shell.execute_reply.started":"2022-05-29T07:04:07.886831Z","shell.execute_reply":"2022-05-29T07:04:08.598002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Tensor = torch.cuda.FloatTensor\n\nfor epoch in tqdm(range(epochs)):\n    for i, (imgs, _) in enumerate(dataloader):\n\n        # Adversarial ground truths\n        valid = Variable(Tensor(imgs.size(0), 1).fill_(1.0), requires_grad=False)\n        fake = Variable(Tensor(imgs.size(0), 1).fill_(0.0), requires_grad=False)\n\n        # Configure input\n        real_imgs = Variable(imgs.type(Tensor))\n\n        # -----------------\n        #  Train Generator\n        # -----------------\n\n        gen_opt.zero_grad()\n\n        # Sample noise as generator input\n        noise = Variable(noise_vector(imgs.shape[0], z_dim))\n        \n        \n        # Generate a batch of images\n        gen_imgs = gen(noise)\n        #print(gen_imgs.shape)\n        dis_out = dis(gen_imgs)\n        #print(dis_out.shape)\n        \n        # Loss measures generator's ability to fool the discriminator\n        g_loss = adv_loss(dis(gen_imgs), valid)\n\n        g_loss.backward()\n        gen_opt.step()\n\n        # ---------------------\n        #  Train Discriminator\n        # ---------------------\n\n        \n        dis_opt.zero_grad()\n\n        # Measure discriminator's ability to classify real from generated samples\n        real_loss = adv_loss(dis(real_imgs), valid)\n        fake_loss = adv_loss(dis(gen_imgs.detach()), fake)\n        d_loss = (real_loss + fake_loss) / 2\n\n        d_loss.backward()\n        dis_opt.step()\n    \n        batches_done = epoch * len(dataloader) + i\n        if batches_done % sample_interval == 0:\n            save_image(gen_imgs.data[:25], \"images/%d.png\" % batches_done, nrow=5, normalize=True)\n    '''\n    if batches_done % 20 == 0:\n        print(\n        \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n        % (epoch, epochs, i, len(dataloader), d_loss.item(), g_loss.item())\n        )\n\n    '''\n    \n        ","metadata":{"execution":{"iopub.status.busy":"2022-05-29T07:04:18.202598Z","iopub.execute_input":"2022-05-29T07:04:18.202976Z","iopub.status.idle":"2022-05-29T09:55:16.404946Z","shell.execute_reply.started":"2022-05-29T07:04:18.202943Z","shell.execute_reply":"2022-05-29T09:55:16.403915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python -m zipfile -c images.zip ./images","metadata":{"execution":{"iopub.status.busy":"2022-05-29T10:05:17.654253Z","iopub.execute_input":"2022-05-29T10:05:17.655138Z","iopub.status.idle":"2022-05-29T10:06:19.200808Z","shell.execute_reply.started":"2022-05-29T10:05:17.655094Z","shell.execute_reply":"2022-05-29T10:06:19.199724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'images.zip')\n","metadata":{"execution":{"iopub.status.busy":"2022-05-29T10:13:35.733647Z","iopub.execute_input":"2022-05-29T10:13:35.734612Z","iopub.status.idle":"2022-05-29T10:13:35.744055Z","shell.execute_reply.started":"2022-05-29T10:13:35.734565Z","shell.execute_reply":"2022-05-29T10:13:35.743121Z"},"trusted":true},"execution_count":null,"outputs":[]}]}